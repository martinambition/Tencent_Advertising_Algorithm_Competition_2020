{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "window= 60\n",
    "embed_size = 128\n",
    "maxlen = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_path ='./data/train_preliminary/'\n",
    "train_ad_path = os.path.join(train_root_path,'ad.csv')\n",
    "train_click_path = os.path.join(train_root_path,'click_log.csv')\n",
    "train_user_path = os.path.join(train_root_path,'user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_train_root_path ='./data/train_semi_final/'\n",
    "semi_train_ad_path = os.path.join(semi_train_root_path,'ad.csv')\n",
    "semi_train_click_path = os.path.join(semi_train_root_path,'click_log.csv')\n",
    "semi_train_user_path = os.path.join(semi_train_root_path,'user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root_path = './data/test/'\n",
    "test_ad_path = os.path.join(test_root_path,'ad.csv')\n",
    "test_click_path = os.path.join(test_root_path,'click_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并 初赛和半决赛数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click_train = pd.read_csv(train_click_path,dtype= {'creative_id':str,'click_times':str,'time':str})\n",
    "df_semi_click_train = pd.read_csv(semi_train_click_path,dtype= {'creative_id':str,'click_times':str,'time':str})\n",
    "df_click_test = pd.read_csv(test_click_path,dtype= {'creative_id':str,'click_times':str,'time':str})\n",
    "df_click_all =  pd.concat([df_click_train,df_semi_click_train,df_click_test], axis=0)\n",
    "df_click_all.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad_train = pd.read_csv(train_ad_path,na_values='\\\\N',dtype= {'creative_id':str,'ad_id': str, 'product_id': str, 'product_category': str,'advertiser_id': str,'industry': str} )\n",
    "df_semi_ad_train = pd.read_csv(semi_train_ad_path,na_values='\\\\N',dtype= {'creative_id':str,'ad_id': str, 'product_id': str, 'product_category': str,'advertiser_id': str,'industry': str} )\n",
    "df_ad_test = pd.read_csv(test_ad_path,na_values='\\\\N',dtype= {'creative_id':str,'ad_id': str, 'product_id': str, 'product_category': str,'advertiser_id': str,'industry': str} )\n",
    "df_ad_all =  pd.concat([df_ad_train,df_semi_ad_train,df_ad_test], axis=0)\n",
    "df_ad_all.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_csv(train_user_path)\n",
    "df_semi_user = pd.read_csv(semi_train_user_path)\n",
    "df_user_all =  pd.concat([df_user,df_semi_user], axis=0)\n",
    "df_user_all.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semi_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc = df_click_all.merge(df_ad_all,on=['creative_id'],how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_docs_withuser = df_doc.merge(df_user_all,on=['user_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>click_times</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>industry</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>30920</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>320815</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>355089</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time  user_id creative_id click_times   ad_id product_id product_category  \\\n",
       "0    9    30920      567330           1  504423      30673                3   \n",
       "1   15   320815      567330           1  504423      30673                3   \n",
       "2   11   355089      567330           1  504423      30673                3   \n",
       "\n",
       "  advertiser_id industry  age  gender  \n",
       "0         32638      319  2.0     1.0  \n",
       "1         32638      319  3.0     1.0  \n",
       "2         32638      319  1.0     1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_docs_withuser.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_click_train\n",
    "# del df_semi_click_train\n",
    "# del df_click_test\n",
    "# del df_ad_train\n",
    "# del df_semi_ad_train\n",
    "# del df_ad_test\n",
    "# del df_doc\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_docs_withuser = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_docs_withuser.to_parquet('./data/cache/ad_docs_withuser.parquet',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 点击序列 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_docs_withuser = pd.read_parquet('./data/cache/ad_docs_withuser.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_docs_withuser = ad_docs_withuser.sort_values('time', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_docs_withuser.fillna('un',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "class epoch_logger(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "        \n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "        \n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggcol = ['creative_id','ad_id','product_id','product_category','advertiser_id','industry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: ' '.join(x.tolist())\n",
    "agg_funcs ={}\n",
    "for col in aggcol:\n",
    "    agg_funcs[col] = func\n",
    "doc = ad_docs_withuser.groupby(['user_id']).agg(agg_funcs)\n",
    "doc = doc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [29:48<00:00, 298.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "new_df ={}\n",
    "new_df['user_id'] = doc['user_id']\n",
    "word_index ={}\n",
    "tokenizer = None\n",
    "for col in tqdm(aggcol):\n",
    "    tokenizer = Tokenizer(lower=False, char_level=False, split=' ')\n",
    "    tokenizer.fit_on_texts(doc[col])\n",
    "    train_x = tokenizer.texts_to_sequences(doc[col])\n",
    "    train_x = pad_sequences(train_x, maxlen=maxlen, value=0,padding='post')\n",
    "    new_df[col] = list(train_x)\n",
    "    word_index[col] =tokenizer.word_index\n",
    "df_final = pd.DataFrame(new_df)\n",
    "df_final.to_parquet('./data/cache/final_padding.parquet_8input',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"./data/cache/word_index.pkl\",\"wb\")\n",
    "pickle.dump(word_index,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: list(x)\n",
    "agg_funcs={}\n",
    "for col in aggcol:\n",
    "    agg_funcs[col] = func\n",
    "doc = ad_docs_withuser.groupby(['user_id']).agg(agg_funcs)\n",
    "doc = doc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creative_id embeding:\n",
      "Epoch #0 start\n",
      "Loss after epoch 0: 73031072.0\n",
      "Epoch #1 start\n",
      "Loss after epoch 1: 15308392.0\n",
      "Epoch #2 start\n",
      "Loss after epoch 2: 13864480.0\n",
      "Epoch #3 start\n",
      "Loss after epoch 3: 12713784.0\n",
      "Epoch #4 start\n",
      "Loss after epoch 4: 11551184.0\n",
      "Epoch #5 start\n",
      "Loss after epoch 5: 7748816.0\n",
      "Epoch #6 start\n",
      "Loss after epoch 6: 0.0\n",
      "Start ad_id embeding:\n",
      "Epoch #0 start\n",
      "Loss after epoch 0: 73136328.0\n",
      "Epoch #1 start\n",
      "Loss after epoch 1: 15349272.0\n",
      "Epoch #2 start\n",
      "Loss after epoch 2: 14047016.0\n",
      "Epoch #3 start\n",
      "Loss after epoch 3: 12917936.0\n",
      "Epoch #4 start\n",
      "Loss after epoch 4: 11545696.0\n",
      "Epoch #5 start\n",
      "Loss after epoch 5: 7221480.0\n",
      "Epoch #6 start\n",
      "Loss after epoch 6: 0.0\n",
      "Start product_id embeding:\n",
      "Epoch #0 start\n",
      "Loss after epoch 0: 45202396.0\n",
      "Epoch #1 start\n",
      "Loss after epoch 1: 23451588.0\n",
      "Epoch #2 start\n",
      "Loss after epoch 2: 4335216.0\n",
      "Epoch #3 start\n",
      "Loss after epoch 3: 3912224.0\n",
      "Epoch #4 start\n",
      "Loss after epoch 4: 3425240.0\n",
      "Epoch #5 start\n",
      "Loss after epoch 5: 2872072.0\n",
      "Epoch #6 start\n",
      "Loss after epoch 6: 2143224.0\n",
      "Start product_category embeding:\n",
      "Epoch #0 start\n",
      "Loss after epoch 0: 5155101.5\n",
      "Epoch #1 start\n",
      "Loss after epoch 1: 4426363.5\n",
      "Epoch #2 start\n",
      "Loss after epoch 2: 3851284.0\n",
      "Epoch #3 start\n",
      "Loss after epoch 3: 3841401.0\n",
      "Epoch #4 start\n",
      "Loss after epoch 4: 3822092.0\n",
      "Epoch #5 start\n",
      "Loss after epoch 5: 3828576.0\n",
      "Epoch #6 start\n",
      "Loss after epoch 6: 4100352.0\n",
      "Start advertiser_id embeding:\n",
      "Epoch #0 start\n",
      "Loss after epoch 0: 72007976.0\n",
      "Epoch #1 start\n",
      "Loss after epoch 1: 11967488.0\n",
      "Epoch #2 start\n",
      "Loss after epoch 2: 10352896.0\n",
      "Epoch #3 start\n",
      "Loss after epoch 3: 8852232.0\n",
      "Epoch #4 start\n",
      "Loss after epoch 4: 7250824.0\n",
      "Epoch #5 start\n",
      "Loss after epoch 5: 5693888.0\n",
      "Epoch #6 start\n",
      "Loss after epoch 6: 3883328.0\n",
      "Start industry embeding:\n",
      "Epoch #0 start\n",
      "Loss after epoch 0: 38486740.0\n",
      "Epoch #1 start\n",
      "Loss after epoch 1: 24766920.0\n",
      "Epoch #2 start\n",
      "Loss after epoch 2: 4214292.0\n",
      "Epoch #3 start\n",
      "Loss after epoch 3: 307968.0\n",
      "Epoch #4 start\n",
      "Loss after epoch 4: 189088.0\n",
      "Epoch #5 start\n",
      "Loss after epoch 5: 98288.0\n",
      "Epoch #6 start\n",
      "Loss after epoch 6: 26048.0\n"
     ]
    }
   ],
   "source": [
    "#product_docs = df_click_all.groupby(['user_id'])['product_id'].apply(list).reset_index(name='product_list')\n",
    "#agg_col = ['ad_id','product_id','product_category','advertiser_id','industry','click_times','time']\n",
    "for col in aggcol:\n",
    "    print(f'Start {col} embeding:')\n",
    "    w2v_model = Word2Vec(doc[col], sg=1,window=window,min_count=1,size=embed_size,iter=7,workers=32, compute_loss=True,callbacks=[epoch_logger()])\n",
    "    w2v_model.wv.save(f\"./model/word2vec_{col}_128.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#advertiser_id 没完成\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# click_time 生成mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_docs_withuser['click_times'] = ad_docs_withuser['click_times'].astype(int)\n",
    "ad_docs_withuser = ad_docs_withuser.groupby(['user_id'])['click_times'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_click = pad_sequences(ad_docs_withuser['click_times'], maxlen=maxlen, value=0,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [2, 1, 1, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_lenth = ad_docs_withuser['click_times'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df ={}\n",
    "new_df['user_id'] = ad_docs_withuser['user_id']\n",
    "new_df['click_times'] =  list(train_click)\n",
    "new_df['click_times_length'] = click_lenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(new_df)\n",
    "df_final.to_parquet('./data/cache/click_times_mask.parquet',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepwalk 生成其他序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deepwalk算法，\n",
    "def generate_deep(log,f1,f2,L):\n",
    "    gc.collect()\n",
    "    print(\"deepwalk:\",f1,f2)\n",
    "    #构建图\n",
    "    dic={}\n",
    "    for item in log[[f1,f2]].values:\n",
    "        try:\n",
    "            str(item[1])\n",
    "            str(item[0])\n",
    "        except:\n",
    "            continue\n",
    "        item_key = 'item_'+str(item[1])\n",
    "        user_key = 'user_'+str(item[0])\n",
    "        if item_key in dic:\n",
    "            dic[item_key].add(user_key)\n",
    "        else:\n",
    "            dic[item_key] = set([user_key])\n",
    "        if user_key in dic:\n",
    "            dic[user_key].add(item_key)\n",
    "        else:\n",
    "            dic[user_key] = set([item_key])\n",
    "    dic_cont={}\n",
    "    for key in dic:\n",
    "        dic[key]=list(dic[key])\n",
    "        dic_cont[key]=len(dic[key])\n",
    "    print(\"creating\")     \n",
    "    #构建路径\n",
    "    path_length=30        \n",
    "    sentences=[]\n",
    "    length=[]\n",
    "    for key in dic:\n",
    "        sentence=[key]\n",
    "        while len(sentence)!=path_length:\n",
    "            key=dic[sentence[-1]][random.randint(0,dic_cont[sentence[-1]]-1)]\n",
    "            if len(sentence)>=2 and key == sentence[-2]:\n",
    "                break\n",
    "            else:\n",
    "                sentence.append(key)\n",
    "        sentence = [key[5:] for key in sentence if key.startswith('item_')]\n",
    "        sentences.append(sentence)\n",
    "        length.append(len(sentence))\n",
    "    print(np.mean(length))\n",
    "    print(len(sentences))\n",
    "    #训练Deepwalk模型\n",
    "    print('training...')\n",
    "    np.random.shuffle(sentences)\n",
    "    model = Word2Vec(sentences, size=L, window=10,min_count=1,sg=1, iter=5,compute_loss=True,callbacks=[epoch_logger()])\n",
    "    model.wv.save(f\"./model/deepwalk/word2vec_{f2}_{str(L)}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agg in aggcol:\n",
    "    generate_deep(df_click_all,'user_id',agg,128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
